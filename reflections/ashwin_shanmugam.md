# Reflection Template (clone → rename to `lastname_firstname.md`)

Table of contents
- [Paper 1 — Collaboration among recruiters and artificial intelligence: removing human prejudices in employment](#paper-1)
- [Paper 2 — Applicants' perception of artificial intelligence in the recruitment process](#paper-2)

---

<a id="paper-1"></a>

## Paper 1 — Collaboration among recruiters and artificial intelligence: removing human prejudices in employment
Chen Z. (2023). Collaboration among recruiters and artificial intelligence: removing human prejudices in employment. Cognition, technology & work (Online), 25(1), 135–149. https://doi.org/10.1007/s10111-022-00716-0

Summary (4–6 sentences):  
- This study addresses the problem that traditional recruiting methods are failing to cope with the global competition for talent, are often inefficient, and are susceptible to human prejudices in employment decisions.
- It explores the transition of talent acquisition from Digital 1.0 to 3.0 (AI-enabled), analyzes the significant role of AI in various recruitment stages, and investigates stakeholder (recruiters, managers, and applicants) perceptions through semi-structured interviews.
- The main findings indicate that AI greatly enhances recruitment efficiency, helps in screening and assessment, and can reduce human cognitive workload, leading to improved candidate-job and candidate-organization fit.
- However, the research also uncovers stakeholder concerns regarding the cost of AI recruitment, legal privacy issues, potential for recruitment bias, and the possibility of AI replacing human recruiters.
- Ultimately, the study contributes recommendations for implementing AI in recruitment practice, emphasizing the need for AI governance, transparency, and a focus on human-AI collaboration.
- It highlights that while AI can manage rule-based, repetitive tasks, human judgment remains crucial for nuanced aspects like cultural fit and managing interpersonal relationships.

Insights:
- Insight 1: AI's Transformative Role in Recruitment - AI significantly changes the recruitment landscape by automating tasks across all stages, from generating job advertisements and refining job searches to screening resumes, assessing candidates, and coordinating communication. This automation not only boosts efficiency but also aims to reduce human cognitive workload and introduce impartiality in candidate screening, making the process faster and potentially fairer than traditional methods.
- Insight 2: The Nuance of Human-AI Collaboration and Trust - While AI offers substantial benefits, its successful adoption hinges on establishing trust and ensuring human oversight. Stakeholders, particularly recruiters and managers, express concerns about the accuracy and fairness of AI decisions, the potential for bias in algorithms, and the desire to maintain control over the final hiring decisions. This underscores the importance of transparent AI algorithms and mechanisms that allow humans to understand, test, and even override AI's recommendations, fostering a cooperative rather than purely autonomous system.
- Insight 3: Addressing AI's Ethical and Practical Challenges - The widespread implementation of AI in recruitment necessitates careful consideration of ethical dilemmas such as algorithmic bias, data privacy, and the impact on human jobs. The study emphasizes the need for AI governance, including periodic training on machine learning to improve accuracy and ensure AI learns without bias. It also clarifies that AI is best seen as a support tool for HR professionals, freeing them for higher-value, strategic tasks that require human persuasion, relationship-building, and cultural understanding, rather than a direct replacement.

Limitations / Risks:
- Limitation / Risk 1: Algorithmic Bias and Discrimination - A significant risk is that AI systems, if trained on historical data containing human biases, can perpetuate or even amplify discrimination based on factors like gender, age, race, or education. This can lead to unfair screening outcomes or discriminatory job advertisements, as illustrated by Amazon's AI hiring tool showing bias against women.
- Limitation / Risk 2: High Cost and Implementation Challenges - The implementation of AI recruitment systems can involve substantial costs, which can be a barrier for many organizations. Furthermore, large-scale digital transformations and AI system deployments often suffer setbacks, requiring a cautious, phased approach. There are also concerns about the accuracy of AI-based assessments, especially if candidates do not take gamified tests seriously or learn to exploit AI questioning patterns, which can undermine the reliability of the evaluation and increase recruitment costs.

Idea for our project:
- Our project could involve designing a prototype for an AI-powered job advertisement generation tool that incorporates a "bias detection and mitigation" module. This module would analyze AI-generated job ad text and targeting parameters, flagging potentially discriminatory language or implicit biases and suggesting neutral alternatives to the human recruiter for review and approval, thereby enhancing fairness and maintaining human control in line with the study's recommendations for AI governance and bias reduction.

---

<a id="paper-2"></a>

## Paper 2 — Applicants' perception of artificial intelligence in the recruitment process
Horodyski, P. (2023). Applicants’ perception of artificial intelligence in the recruitment process. Computers in Human Behavior Reports, 11, 100303. doi:10.1016/j.chbr.2023.100303

Summary (4–6 sentences):  
- This paper addresses the problem of limited literature coverage on applicants' perceptions and experiences of AI technology in hiring processes, as most existing studies focus on the benefits for recruiters and employers.
- It explores these perceptions by conducting a study where 552 job seekers from various nationalities and industries completed an online questionnaire about their experiences with AI tools in recruitment, with the results analyzed using the Technology Acceptance Model (TAM).
- The main findings indicate that applicants generally perceive AI technology positively, viewing it as useful and easy to use, with reduced response time being the most significant advantage.
- However, applicants also identified major drawbacks, including AI's lack of nuance in human judgment, low accuracy and reliability, and immature technology.
- The study's significance lies in extending TAM to the HR field, deepening the understanding of AI implementation from a user perspective, and offering valuable insights to HR managers and software developers for improving AI tools and the candidate experience by addressing identified weaknesses.
- This research highlights that while AI offers efficiency, fostering acceptance requires addressing concerns around human interaction, transparency, and accuracy.

Insights:
- Insight 1: Overall Positive Applicant Perception and Acceptance Drivers - Applicants generally hold a positive perception of AI technology in hiring processes, viewing it as useful and easy to use, which significantly influences their acceptance and willingness to participate in AI-driven recruitments. The study confirmed that Perceived Usefulness (PU) and Perceived Ease of Use (PEoU) are key determinants of applicants' behavioral intention to use AI in recruitment, aligning with the Technology Acceptance Model (TAM). Their satisfaction with AI tools also encourages their use, further supporting the integration of AI in HR.
- Insight 2: Efficiency as a Primary Advantage, but a Strong Preference for Human Nuance - The most significant advantage of AI in recruitment, mentioned by nearly 70% of applicants, is reduced response time, alongside ease of use, improved quality and objectivity of the hiring process, and a better user experience. Despite these efficiency benefits, a major drawback, also cited by almost 70% of respondents, is the AI's lack of nuance in human judgment or "human touch," with participants expressing a preference for human interviewers for more subjective and interpersonal aspects of the process.
- Insight 3: Critical Challenges in AI Maturity, Accuracy, and Transparency - Beyond the lack of human judgment, applicants identify low accuracy, reliability, and immature technology as significant drawbacks. Specific concerns include issues with spoken word or text recognition, high dependence on internet connection, algorithms giving "silly answers" due to incorrect detection of intent, biases, and inadequate optimization for video interviews. A notable concern for 34.8% of participants is the lack of transparency, which leads to fears of being unfairly overlooked because they do not know what the AI tool is "searching for".

Limitations / Risks:
- Limitation / Risk 1: Limited Scope and Unexplored Ethical and Legal Dimensions - A primary limitation of this research is its narrow focus on only four specific factors (usefulness, ease of use, satisfaction, and perceived attractiveness) influencing applicant perception of AI tools, which limits its generalizability to other potential influencing factors or different HR technologies. Critically, despite being mentioned as drawbacks by a significant portion of respondents, ethical concerns, privacy implications, and legal issues were not fully explored within the study's scope.
- Limitation / Risk 2: Algorithmic Bias and Dehumanization of the Recruitment Process - A significant risk is the potential for algorithmic bias, where AI systems, if trained on historically biased data, can perpetuate or even amplify discrimination against certain groups, as demonstrated by Amazon's AI recruitment tool favoring male applicants. Furthermore, the pervasive concern among applicants is the AI's inherent lack of "human touch" and nuance in judgment, which can lead to impersonal experiences and the feeling that good candidates might "slip through the cracks" if the AI cannot account for unique circumstances, experiences, or complex queries.

Idea for our project:
- Our project could focus on developing an AI-driven interview feedback system designed to enhance transparency and address the "lack of human nuance" concern by providing applicants with clear, anonymized feedback on how their responses were processed by the AI, and allowing them to flag perceived AI misinterpretations or biases for human review. This system would also gather applicant satisfaction scores specifically on the AI's ability to understand complex answers and its perceived fairness, directly informing AI algorithm improvements for a more trusted and effective candidate experience.

## Acknowledgements
This reflection was developed with the assistance of generative AI tools, specifically utilizing Ai2 Asta for article searching and ChatGPT-5 for key information extraction. All content has been thoroughly reviewed, rephrased, and validated by the author to ensure accuracy and maintain authenticity of the analysis.
